{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Define the convolutional neural network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, kernel_size, stride, padding):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \"\"\"\n",
    "        Set the number of input and output channels, kernel size, stride, and padding.\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Get the batch size and dimensions of the input tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, _, input_width, input_height = x.size()\n",
    "\n",
    "        # Compute the output width and height.\n",
    "        #\n",
    "        output_width = (input_width + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        output_height = (input_height + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "\n",
    "        # Create output tensor with the specified dimensions.\n",
    "        #\n",
    "        output = torch.zeros(batch_size, self.output_channels, output_width, output_height)\n",
    "\n",
    "        # Loop through the batch and apply the convolution operation to each sample.\n",
    "        #\n",
    "        for i in range(batch_size):\n",
    "            for j in range(self.output_channels):   # Loop through the output channels.\n",
    "                for k in range(output_height):  # Loop through the output height.\n",
    "                    for l in range(output_width):   # Loop through the output width.\n",
    "                        output_pos = (i, j, k, l)   # Loop through the output width.\n",
    "\n",
    "                        ## Compute the start and end indices for the kernel.\n",
    "                        # along the width and height dimensions.\n",
    "                        #\n",
    "                        start_w = l * self.stride\n",
    "                        end_w = start_w + self.kernel_size\n",
    "                        start_h = k * self.stride\n",
    "                        end_h = start_h + self.kernel_size\n",
    "\n",
    "                        # Get the submatrix of the input tensor that the kernel will be applied to.\n",
    "                        #\n",
    "                        input_submatrix = x[i, :, start_w:end_w, start_h:end_h]\n",
    "\n",
    "                        # Apply the convolution operation to the submatrix and store the result in the output tensor.\n",
    "                        #\n",
    "                        output[output_pos] = torch.sum(input_submatrix)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_grad):\n",
    "        \"\"\"\n",
    "        Use PyTorch's Automatic Differentiation to compute the gradients of the output \n",
    "        w.r.t. the model's parameters and the input tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        output_grad.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5389,  2.3328,  1.0332, -0.2631, -1.7795],\n",
      "          [ 2.6077,  3.4282, -0.4960, -1.6046, -2.6826],\n",
      "          [-0.1072, -0.2893, -2.0724, -3.0228, -2.4961],\n",
      "          [-0.8663,  0.0636, -2.7949, -3.3064, -2.4923],\n",
      "          [-1.4686, -1.7661, -2.3913, -2.3756, -1.4972]]]])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" \n",
    "    Create a convolutional neural network\n",
    "    \"\"\"\n",
    "\n",
    "    model = ConvNet(input_channels=1, output_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    # Define the input tensor.\n",
    "    #\n",
    "    x = torch.randn(1, 1, 5, 5)\n",
    "\n",
    "    # Apply the convolutional neural network to the input tensor and print output.\n",
    "    #\n",
    "    output = model(x)\n",
    "    print(output)\n",
    "\n",
    "    # Move the model to the GPU\n",
    "    #\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f166fe30ea6bbce3438a22ffdf62dd5f327ee3c3b935cf331c63fb6525b3ba3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
