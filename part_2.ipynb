{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\chand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Instance-label split for Train and Test.\\n#\\ntrain_instances = torch.cat([instance for instance, label in trainloader])\\ntrain_labels = torch.cat([label for instance, label in trainloader])\\n\\ntest_instances = torch.cat([instance for instance, label in testloader])\\ntest_labels = torch.cat([label for instance, label in testloader])\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Instance-label split for Train and Test.\n",
    "#\n",
    "train_instances = torch.cat([instance for instance, label in trainloader])\n",
    "train_labels = torch.cat([label for instance, label in trainloader])\n",
    "\n",
    "test_instances = torch.cat([instance for instance, label in testloader])\n",
    "test_labels = torch.cat([label for instance, label in testloader])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnP2(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network Architecture based on the description. \n",
    "    * Layers initialization.\n",
    "    * Forward() function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CnnP2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(2)\n",
    "        self.linear = nn.Linear(64 * 3 * 3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data, iter):\n",
    "    \n",
    "    model = CnnP2()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(iter):  # loop over the dataset multiple times\n",
    "\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, data in enumerate(data, 0):\n",
    "            \n",
    "            inputs, labels = data[:2]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            #\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(f'[Iter {epoch+1}] - Accuracy: {100 * correct // total} %')\n",
    "\n",
    "    print('Finished Training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling Train set.\n",
    "#\n",
    "train = torchvision.datasets.MNIST(root='MNIST/processed', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "## Split 60K to 50K and 10K for Train and Val sets.\n",
    "# Followed by applying loaders.\n",
    "#\n",
    "train_dl, valid_dl = torch.utils.data.random_split(train, [50000, 10000])\n",
    "trainloader = torch.utils.data.DataLoader(train_dl, batch_size=16, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valid_dl, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "# Calling Test set.\n",
    "#\n",
    "test = torchvision.datasets.MNIST(root='MNIST/processed', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1] - Accuracy: 100.0 %\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(trainloader, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AugMix', 'AutoAugment', 'AutoAugmentPolicy', 'CenterCrop', 'ColorJitter', 'Compose', 'ConvertImageDtype', 'ElasticTransform', 'FiveCrop', 'GaussianBlur', 'Grayscale', 'InterpolationMode', 'Lambda', 'LinearTransformation', 'Normalize', 'PILToTensor', 'Pad', 'RandAugment', 'RandomAdjustSharpness', 'RandomAffine', 'RandomApply', 'RandomAutocontrast', 'RandomChoice', 'RandomCrop', 'RandomEqualize', 'RandomErasing', 'RandomGrayscale', 'RandomHorizontalFlip', 'RandomInvert', 'RandomOrder', 'RandomPerspective', 'RandomPosterize', 'RandomResizedCrop', 'RandomRotation', 'RandomSolarize', 'RandomVerticalFlip', 'Resize', 'TenCrop', 'ToPILImage', 'ToTensor', 'TrivialAugmentWide', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_pil_constants', '_presets', 'autoaugment', 'functional', 'functional_pil', 'functional_tensor', 'transforms']\n"
     ]
    }
   ],
   "source": [
    "print(dir(transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(degrees=20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0, 1)\n",
    "    # transforms.RandomResizedCrop(size=128, scale=(0.8, 1.0)),\n",
    "    # \n",
    "])\n",
    "\n",
    "train_aug = torchvision.datasets.MNIST(root=\"MNIST/Augmented\", train=True, download=True, transform=data_transform)\n",
    "train_dl_aug, valid_dl_aug = torch.utils.data.random_split(train_aug, [50000, 10000])\n",
    "trainloader_aug = torch.utils.data.DataLoader(train_dl_aug, batch_size=16, shuffle=True, num_workers=2)\n",
    "valloader_aug = torch.utils.data.DataLoader(valid_dl_aug, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 1] - Accuracy: 87.0 %\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(trainloader_aug, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f166fe30ea6bbce3438a22ffdf62dd5f327ee3c3b935cf331c63fb6525b3ba3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
